---
layout: post
title:  "Kotlin Sequence를 활용한 거래내역 조회 최적화"
author: 김연우
date: '2024-09-17'
thumbnail: /assets/img/posts/transactions.jpg
keywords: 최적화, 시퀀스, 코틀린, 토스뱅크
---

최근에 블로그 글을 쓰는데에 좀 소홀했다. 주말마다 등산을 다니는데, 몇 주간은 주말에 1박2일로 부모님과 등산 여행을 가는일이 잦아서 글을 쓰는게 좀 힘들었다. 그래도 다시 마음을 다잡고 글을 써보고자 한다. 3MR 중에 거래내역 조회 관련해서 시퀀스를 적용해서 성능을 크게 올린 일이 한번 있었다. 오늘은 그 일에 대해 정리해보고자 한다.

### 기존 구현과 개선 계획
토스뱅크의 거래내역 조회에는 생각보다 굉장히 많은 작업이 들어간다. 간단하게 생각하면 “거래내역 테이블”에서 기간이나 검색어 조건에 맞는 거래내역을 SQL로 검색해와서 그대로 응답하는것을 상상하겠지만, 사실은 그렇지 않다. 데이터 중복이나 일관성을 위해 테이블에는 저장되지 않은 값을 응답 전에 추가하기도 하고, 반대로 테이블에는 저장돼있지만 전산 및 회계 상의 데이터라 사용자에게 보여줄 필요가 없을 경우에는 제외하기도 한다. 그렇기 때문에 필연적으로 거래내역 조회는 DB에서 읽어온 거래내역 리스트를 순회하며 필요한 처리를 수행한다.

거래내역을 filtering, transforming, decorating하는 작업들을 거치기 때문에 기존의 구현은 DB에서 조회한 거래내역 리스트를 변환이 필요한 만큼 순회하는 구조로 되어있었다. 예를 들자면 아래와 같다.

```
val txs = getFromDatabase() // List<Transaction>
txs1 = txs.map { transform1(it) }
txs2 = txs1.map { transform2(it) }
txs3 = txs2.filter()
```

여기에 추가로 필터링 과정을 위해 다시 데이터베이스 조회가 필요한 작업이 있어서 이 부분을 병렬로 작업하는 코드가 위 예시의 `filter` 코드 내부에 아래와 같이 있었다.

```
val txToHide = ConcurrentArrayList()
runBlocking {
	txs.forEach {
		launch {
			if (it.shouldHide()) txToHide.add(it)
		}
	}
}
txs.filterNot { it in txToHide }
```

위 코드들을 보면, 전체적으로 중간 표현의 리스트를 아주 많이 생성하는 코드임을 볼 수 있다. 리스트를 생성하는 것은 그 자체로도 오버헤드가 꽤 있으며, 중간 표현의 크기가 클 수록 오버헤드 또한 커진다. 토스뱅크의 거래내역 조회같은 경우 많은 요청이 토스 홈의 타임라인에서 오고 있고, 이때의 응답 크기는 한번의 요청에 최대 2000개이기 때문에 꽤나 많은 메모리 할당과 중간 표현을 위한 작업이 있다고 볼 수 있다.

이것을 개선하기 위해 코드 리뷰 당시에 시퀀스 사용을 검토했다. Kotlin Sequence는 lazy evaluation이 특징이고 list와는 다르게 중간 표현을 생성하지 않고 하나의 element에 대해 모든 작업을 한번에 수행하여 결과를 만들어내기 때문에 이러한 여러 단계의 절차를 수행하는 작업에 효과적이다.

또한, launch로 숨길 거래내역 리스트를 모아서 거래내역을 필터링하던 기존 방식과는 달리, async를 사용해서 별도 리스트 없이 거래내역을 필터링할 수 있게 개선하였다. 개선된 코드의 형태는 아래와 같다.
```
runBlocking {
	txs.map {
		async { it.takeIf { it.shouldHide().not() } }
	}.mapNotNull { it.await() }
}
```

위 코드처럼 `async`를 통해서 `Deferred` 객체를 생성하면, 컬렉션 접근에 대한 동시성 접근을 생각할 필요도 없고, 별도 컬렉션을 생성할 필요도 없어서 간결하고 효율적이다.

이렇게 개선한 코드를 실제로 운영에 적용하기 전에 테스트로 성능 개선이 있음을 입증했다. 당시 10000개 트랜잭션(숨길 내역, 숨기지 않을 내역)을 랜덤으로 생성하여 넣은 후 거래내역 조회를 수행하는 테스트 코드를 작성해서 돌린 결과에 의하면, 메모리 사용량은 216MB -> 212MB로 경미한 개선을 보였고, 수행시간은 450ms -> 369ms로 18%정도 개선을 보였다 (Intellij Profiler Total Time 기준).

### 적용 과정에서의 문제점
적용하는 과정에서 두번 정도 문제가 생겨서 중간에 롤백했다. 첫번째 문제는 thread-safe한 collection을 사용하지 않아서 발생하는 문제였다. 거래내역 필터링 과정에서 **관련된 계좌를 먼저 조회해서 인메모리 맵에 캐싱하는 부분**이 있었는데, 이러한 로직이 있다는 것은 인지하고 있었으나 변경사항으로 인해 이 부분이 병렬화되고, 컬렉션 또한 thread-safe한 컬렉션을 사용하게 바뀌어야 한다는 부분을 인지하지 못했다.

또한 에러메시지가 `LinkedHashMap$Entry cannot be cast to class HashMap$TreeNode` 와 같이 ConcurrentModificationException (일반적으로 발생하는 동시접근 exception)이 아닌 에러로 와서 더 혼란스러웠는데, 알고 보니 이 에러메시지는 자바의 HashMap 구현과 관련이 있었다. 자바에서 HashMap은 버킷 길이가 일정 수 이상이면 LinkedList에서 RedBlackTree로 자료구조를 변경하는데, 이 과정 중에 다른 쓰레드에서 HashMap에 접근하는 경우에 이와 같은 에러메시지로 떨어지는 것 같다. (버킷 길이란 collision이 났을때 하나의 hash value에 저장되는 값들의 개수를 의미한다)

에러를 인지하고 ConcurrentHashMap으로 자료구조를 변경해서 배포하는데, 이번에는 모니터링 과정에서 이상함을 느껴서 롤백했다. 캐싱의 주 목적은 거래내역 필터링 과정에서 반복적으로 계좌 서버에 같은 계좌 정보를 요청하는 것을 막기 위함이었는데, 카나리 배포 과정에서 계좌 서버로의 요청이 증가하는 것이 관찰되었다.

이는 마찬가지로 병렬화로 인해 생기는 문제였다. 기존의 구현은 접근하는 계좌정보들을 계좌서버에 전부 요청해서 결과값을 캐싱해놓고 필터링을 시작하는 구조였기 때문에 필터링하는 단계에서는 무조건 cache hit이 발생하는 구조였는데, 구조를 변경하면서 각 거래내역이 병렬적으로 계좌정보를 요청하게 되어 cache hit이 발생하지 못하고 동시다발적으로 계좌 서버에 같은 계좌 정보를 요청하는 것이었다.

해결하기 위해서는 원래의 구현처럼 먼저 계좌정보를 요청하는 방법도 있었으나, 앞서 얘기했듯이 나는 이 거래내역 필터링 작업 과정에서 생성되는 중간 표현들을 줄이고 간결하게 작동할 수 있게 최적화하고 싶었다. 그래서 결국 캐시를 채우는 부분만 직렬화하는 방법을 선택했다. 이것을 해결하는 과정에서 또 알 수 있었던 재밌는 부분은, 자바의 ConcurrentHashMap 구현체의 method중 하나인 `getOrPut`은 동시접근 제어를 하지 않으나, `computeIfAbsent`는 compute할때 내부 구현에서 synchronized 블럭을 사용하기 때문에 동시접근 제어가 된다는 사실이었다. 따라서 기존 코드에서 캐시에 접근하는 부분을 직렬화하기 위해 필요한 수정은 딱 한줄이었다.
```
// cache.getOrPut{ accountApiClient.get() }
cache.computeIfAbsent { accountApiClient.get() }
```

### 결과
우여곡절도 많고 기능 변화가 있는것도 아닌 단순 리팩토링 및 최적화 작업이어서 사실 중간에 회의도 들었다. 거의 일주일을 이 이슈를 붙잡고 있었는데 문제만 생기고 성능이 좋아질지는 확신도 못하겠고.. 그랬는데 다행히 성능에 많은 개선이 있는것을 확인할 수 있었다. 성능 개선 확인을 위해서 토스뱅크의 SRE (Software Reliability Engineer)를 해주고 계시는 태웅님께 프로파일링을 요청드렸고, 그 결과 거래내역 파이프라인 서비스에서 사용되는 CPU 사용량은 35%가 개선되고, 메모리 사용량은 14%가 개선된 것을 확인했다. 전체 서비스로 봤을때도 CPU가 15% 정도 개선된 것을 확인해주셨다. 추가로 거래내역 조회 latency에 있어서도 p95 latency 기준으로 15% (85 -> 70ms) 정도 개선이 있었다.

토스뱅크에 와서 나에게 맡겨진 일이 아닌 내가 주도한 첫번째 일이었는데 결과가 좋게 나와서 많이 뿌듯했다. 그리고 앞으로도 뭔가 이렇게 바꿔봐야겠다 하는 결심이 들면 흔들리지 않고 주도적으로 추진해봐야겠다고 생각하게 되었다. 
